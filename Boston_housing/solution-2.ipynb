{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython, graphviz, sklearn_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "import os\n",
    "import feather\n",
    "import math\n",
    "import re\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer, StandardScaler\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype\n",
    "from sklearn.ensemble import forest\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_trees(m, fn, n_jobs=8):\n",
    "    return list(ProcessPoolExecutor(n_jobs).map(fn, m.estimators_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_tree(t, df, size=10, ratio=0.6, precision=0):\n",
    "    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True,\n",
    "                      special_characters=True, rotate=True, precision=precision)\n",
    "    IPython.display.display(graphviz.Source(re.sub('Tree {', f'Tree {{ size = {size}; ratio={ratio}', s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feature_imp(m, df):\n",
    "    return pd.DataFrame({'cols': df.columns, 'importance': m.feature_importances_}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datepart(df, fldname, drop=True, time=False):\n",
    "    \"\"\"add_datepart converts a column of df from a datetime64 to many columns containing\n",
    "    the information from the date. This applies changes inplace.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas data frame. df gain several new columns.\n",
    "    fldname: A string that is the name of the date column you wish to expand.\n",
    "        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n",
    "    drop: If true then the original date column will be removed.\n",
    "    time: If true time features: Hour, Minute, Second will be added.\n",
    "\n",
    "    Examples:\n",
    "    ---------\n",
    "\n",
    "    >>> df = pd.DataFrame({ 'A' : pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000'], infer_datetime_format=False) })\n",
    "    >>> df\n",
    "\n",
    "        A\n",
    "    0   2000-03-11\n",
    "    1   2000-03-12\n",
    "    2   2000-03-13\n",
    "\n",
    "    >>> add_datepart(df, 'A')\n",
    "    >>> df\n",
    "\n",
    "        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n",
    "    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n",
    "    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n",
    "    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n",
    "    \"\"\"\n",
    "    fld = df[fldname]\n",
    "    fld_dtype = fld.dtype\n",
    "    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "        fld_dtype = np.datetime64\n",
    "\n",
    "    if not np.issubdtype(fld_dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "    if time: attr = attr + ['Hour', 'Minute', 'Second']\n",
    "    for n in attr: df[targ_pre + n] = getattr(fld.dt, n.lower())\n",
    "    df[targ_pre + 'Elapsed'] = fld.astype(np.int64) // 10 ** 9\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cats(df):\n",
    "    for n,c in df.items():\n",
    "        if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()\n",
    "            \n",
    "            \n",
    "def apply_cats(df, trn):\n",
    "    for n, c in df.items():\n",
    "        if (n in trn.columns) and (trn[n].dtype.name=='category'):\n",
    "            df[n] = pd.Categorical(c, categories=trn[n].cat.categories, ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(df, col, name, max_n_cat):\n",
    "    if not is_numeric_dtype(col) and ( max_n_cat is None or len(col.cat.categories)>max_n_cat):\n",
    "        df[name] = col.cat.codes+1\n",
    "        \n",
    "        \n",
    "def get_sample(df, n):\n",
    "    idxs = sorted(np.random.permutation(len(df))[:n])\n",
    "    return df.iloc[idxs].copy()\n",
    "\n",
    "\n",
    "def fix_missing(df, col, name, na_dict):\n",
    "    if is_numeric_dtype(col):\n",
    "        if pd.isnull(col).sum() or (name in na_dict):\n",
    "            df[name+'_na'] = pd.isnull(col)\n",
    "            filler = na_dict[name] if name in na_dict else col.median()\n",
    "            df[name] = col.fillna(filler)\n",
    "            na_dict[name] = filler\n",
    "    return na_dict\n",
    "\n",
    "\n",
    "def scale_vars(df, mapper):\n",
    "    warnings.filterwarnings('ignore', category=sklearn.exceptions.DataConversionWarning)\n",
    "    if mapper is None:\n",
    "        map_f = [([n], StandardScaler()) for n in df.columns if is_numeric_dtype(df[n])]\n",
    "        mapper = DataFrameMapper(map_f).fit(df)\n",
    "    df[mapper.transformed_name_] = mapper.transform(df)\n",
    "    return mapper\n",
    "        \n",
    "        \n",
    "def proc_df(df, y_fld, skip_flds=None, ignore_flds=None, do_scale=False, na_dict=None,\n",
    "            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n",
    "    if not skip_flds: skip_flds=[]\n",
    "    if not ignore_flds: ignore_flds=[]\n",
    "    if subset:\n",
    "        df = get_sample(df, subset)\n",
    "    else:\n",
    "        df = df.copy()\n",
    "    ignored_flds = df.loc[:, ignore_flds]\n",
    "    df.drop(ignore_flds, axis=1, inplace=True)\n",
    "    if preproc_fn:\n",
    "        preproc_fn(df)\n",
    "    if y_fld is None:\n",
    "        y = None\n",
    "    else:\n",
    "        if not is_numeric_dtype(df[y_fld]):\n",
    "            df[y_fld] = df[y_fld].cat.codes\n",
    "        y = df[y_fld].values\n",
    "        skip_flds += [y_fld]\n",
    "    df.drop(skip_flds, axis=1, inplace=True)\n",
    "    \n",
    "    if na_dict is None:\n",
    "        na_dict = {}\n",
    "    else:\n",
    "        na_dict = na_dict.copy()\n",
    "    na_dict_initial = na_dict.copy()\n",
    "    for n, c in df.items():\n",
    "        na_dict = fix_missing(df, c, n, na_dict)\n",
    "    if len(na_dict_initial.keys()) > 0:\n",
    "        df.drop([a + '_na' for a in list(set(na_dict.keys()) - set(na_dict_initial.keys()))], axis=1, inplace=True)\n",
    "    if do_scale:\n",
    "        mapper = scale_vars(df, mapper)\n",
    "    for n, c in df.items():\n",
    "        numericalize(df, c, n, max_n_cat)\n",
    "    df = pd.get_dummies(df, dummy_na=True)\n",
    "    df = pd.concat([ignored_flds, df], axis=1)\n",
    "    res = [df, y, na_dict]\n",
    "    if do_scale:\n",
    "        res = res + mapper\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_vals(a, n):\n",
    "    return a[:n].copy(), a[n:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(x, y):\n",
    "    return math.sqrt(((x - y)**2).mean())\n",
    "\n",
    "log = lambda x: np.log1p(x)\n",
    "\n",
    "kaggle_pred = lambda x: x / 100\n",
    "\n",
    "def print_score(m, X_train, y_train, X_test, y_test):\n",
    "    res = [rmse(m.predict(X_train), y_train),\n",
    "           rmse(m.predict(X_test), y_test),\n",
    "           m.score(X_train, y_train), m.score(X_test, y_test)]\n",
    "    if hasattr(m, 'oob_score_'):\n",
    "        res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(f'{PATH}train.csv')\n",
    "df_test =  pd.read_csv(f'{PATH}test.csv')\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -2 data/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(f'{PATH}train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all(df):\n",
    "    with pd.option_context('display.max_rows', 1000, 'display.max_columns', 1000):\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all(df_raw.head().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all(df_raw.tail().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all(df_test.describe(include='all').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all(df_raw.describe(include='all').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_raw.SalePrice = np.log(df_raw.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.SalePrice = np.log1p(df_raw.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cats(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.SaleCondition.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all(df_raw.isnull().sum().sort_index()/len(df_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y, nas = proc_df(df_raw, 'SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.columns), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1, n_estimators=10)\n",
    "m.fit(df, y)\n",
    "m.score(df,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_valid = 400\n",
    "n_trn = len(df)-n_valid\n",
    "raw_train, raw_valid = split_vals(df_raw, n_trn)\n",
    "X_train, X_valid = split_vals(df, n_trn)\n",
    "y_train, y_valid = split_vals(y, n_trn)\n",
    "X_train.shape, y_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1, n_estimators=10)\n",
    "%time m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_result(m, df_test):\n",
    "#     df_raw_test = df_test.copy()\n",
    "#     apply_cats(df_raw_test, df_raw)\n",
    "#     df_t, _, _ = proc_df(df_raw_test, None, na_dict=nas)\n",
    "#     y_pred = m.predict(df_t)\n",
    "    \n",
    "#     submission = pd.DataFrame({\n",
    "#         \"Id\": df_test[\"Id\"],\n",
    "#         \"SalePrice\": y_pred\n",
    "#     })\n",
    "    \n",
    "#     submission.to_csv('submission-Feb-2-2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn, y_trn, nas = proc_df(df_raw, 'SalePrice', subset=10000, na_dict=nas)\n",
    "X_train, _ = split_vals(df_trn, 1200)\n",
    "y_train, _ = split_vals(y_trn, 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=10, n_jobs=-1)\n",
    "%time m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=1, max_depth=3, bootstrap=False, n_jobs=1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_tree(m.estimators_[0], df_trn, precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=1, bootstrap=False, n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=20, n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.stack([t.predict(X_valid) for t in m.estimators_])\n",
    "preds[:, 0], np.mean(preds[:, 0]), y_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([metrics.r2_score(y_valid, np.mean(preds[:i+1], axis=0)) for i in range(20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=20, n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=80, n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn, y_trn, nas = proc_df(df_raw, 'SalePrice')\n",
    "X_train, X_valid = split_vals(df_trn, n_trn)\n",
    "y_train, y_valif = split_vals(y_trn, n_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn, y_trn, nas = proc_df(df_raw, 'SalePrice')\n",
    "X_train, X_valid = split_vals(df_trn, 1000)\n",
    "y_train, y_valid = split_vals(y_trn, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, n_jobs=-1, oob_score=True)\n",
    "%time m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence based on tree Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn, y_trn, nas = proc_df(df_raw, 'SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_valid = 460\n",
    "n_trn = len(df_trn) - n_valid\n",
    "raw_train, raw_valid = split_vals(df_raw, n_trn)\n",
    "X_train, X_valid = split_vals(df_trn, n_trn)\n",
    "y_train, y_valid = split_vals(y, n_trn)\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time preds = np.stack([t.predict(X_valid) for t in m.estimators_])\n",
    "np.mean(preds[:, 0]), np.std(preds[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(t):\n",
    "    return t.predict(X_valid)\n",
    "\n",
    "%time preds = np.stack(parallel_trees(m, get_preds))\n",
    "np.mean(preds[:, 0]), np.std(preds[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = raw_valid.copy()\n",
    "x['pred_std'] = np.std(preds, axis=0)\n",
    "x['pred'] = np.mean(preds, axis=0)\n",
    "x.MSZoning.value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flds = ['MSZoning', 'SalePrice', 'pred', 'pred_std']\n",
    "zone_summ = x[flds].groupby('MSZoning', as_index=False).mean()\n",
    "zone_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_valid.MSSubClass.value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flds = ['MSSubClass', 'SalePrice', 'pred', 'pred_std']\n",
    "class_summ = x[flds].groupby('MSSubClass', as_index=False).mean()\n",
    "class_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(class_summ.pred_std/ class_summ.pred).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots_adjust(bottom=.25, left=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf_feature_imp(m, df_trn); fi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.plot('cols', 'importance', figsize=(17, 10), legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fi(fi):\n",
    "    return fi.plot('cols', 'importance', 'barh', figsize=(12, 7), legend=False)\n",
    "\n",
    "plot_fi(fi[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = fi[fi.importance>0.004].cols; len(to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keep = df_trn[to_keep].copy()\n",
    "\n",
    "X_train, X_valid = split_vals(df_keep, n_trn)\n",
    "\n",
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf_feature_imp(m, df_keep)\n",
    "plot_fi(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffle = df_keep.copy()\n",
    "np.percentile\n",
    "df_shuffle.OverallQual = sklearn.utils.shuffle(df_shuffle.OverallQual).values\n",
    "df_shuffle.OverallQual[15], df_shuffle.OverallQual[15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = split_vals(df_shuffle, n_trn)\n",
    "\n",
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_test(df, flds=None):\n",
    "    if flds is None:\n",
    "        flds = df.columns.values\n",
    "    for fld in flds:\n",
    "        df_shuffle = df.copy()\n",
    "        df_shuffle[fld] = sklearn.utils.shuffle(df_shuffle[fld]).values\n",
    "        X_train, X_valid = split_vals(df_shuffle, n_trn)\n",
    "        m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=True)\n",
    "        m.fit(X_train, y_train)\n",
    "        print(fld, end='=> ')\n",
    "        print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_test(df_keep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn2, y_trn, nas = proc_df(df_raw, 'SalePrice', max_n_cat=4)\n",
    "X_train, X_valid = split_vals(df_trn2, n_trn)\n",
    "\n",
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.6, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf_feature_imp(m, df_trn2)\n",
    "plot_fi(fi[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = fi[fi.importance>=0.004].cols; len(to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keep = df_trn2[to_keep].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Redundant Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy as hc\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.round(scipy.stats.spearmanr(df_keep).correlation, 4)\n",
    "corr_condensed = hc.distance.squareform(1-corr)\n",
    "z = hc.linkage(corr_condensed, method='average')\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "dendrogram = hc.dendrogram(z, labels=df_keep.columns, orientation='left', leaf_font_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oob(df):\n",
    "    m = RandomForestRegressor(n_estimators=30, min_samples_leaf=5, max_features=0.6, n_jobs=-1, oob_score=True)\n",
    "    x, _ = split_vals(df, n_trn)\n",
    "    m.fit(x, y_train)\n",
    "    return m.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_oob(df_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ('GarageCars', 'ExterQual_TA', 'FullBath', '1stFlrSF', 'LotFrontage', 'BsmtFinSF1'):\n",
    "    print(c, get_oob(df_keep.drop(c, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['1stFlrSF', 'LotFrontage', 'GarageCars']\n",
    "get_oob(df_keep.drop(to_drop, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keep.drop(to_drop, axis=1, inplace=True)\n",
    "X_train, X_valid = split_vals(df_keep, n_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.7, n_jobs=-1, oob_score=True)\n",
    "m.fit(X_train, y_train)\n",
    "print_score(m, X_train, y_train, X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution(m, df_test, df_raw, nas, df, i):\n",
    "    apply_cats(df_test, df_raw)\n",
    "    df_test, _, _ = proc_df(df_test, None, na_dict=nas, max_n_cat=4)\n",
    "    df_test = df_test[list(df.columns.values)]\n",
    "    y_pred = m.predict(df_test)\n",
    "    submission = pd.DataFrame({\n",
    "            \"Id\": df_test2[\"Id\"],\n",
    "            \"SalePrice\": np.expm1(y_pred)\n",
    "        })\n",
    "    submission.to_csv(f'submission-Feb-8-{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.7, n_jobs=-1, oob_score=True)\n",
    "m.fit(df_keep, y)\n",
    "solution(m, df_test, df_raw, nas, df_keep, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_cats(df_test, df_raw)\n",
    "df_test, _, _ = proc_df(df_test, None, na_dict=nas, max_n_cat=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[list(df_keep.columns.values)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_keep.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_cats(df_test, df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test, _, _ = proc_df(df_test, None, na_dict=nas, max_n_cat=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = m.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn[df_trn2.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df_trn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
